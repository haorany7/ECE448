{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS440/ECE448 Spring 2023\n",
    "# MP10: Markov decision processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is to download this file: <a href=\"mp10.zip\">mp10.zip</a>.  It has the following content:\n",
    "\n",
    "* `submitted.py`: Your homework. Edit, and then submit to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.\n",
    "* `mp10_notebook.ipynb`: This is a <a href=\"https://anaconda.org/anaconda/jupyter\">Jupyter</a> notebook to help you debug.  You can completely ignore it if you want, although you might find that it gives you useful instructions.\n",
    "* `grade.py`: Once your homework seems to be working, you can test it by typing `python grade.py`, which will run the tests in `tests/tests_visible.py`.\n",
    "* `tests/test_visible.py`: This file contains about half of the <a href=\"https://docs.python.org/3/library/unittest.html\">unit tests</a> that Gradescope will run in order to grade your homework.  If you can get a perfect score on these tests, then you should also get a perfect score on the additional hidden tests that Gradescope uses.\n",
    "* `solution.json`: This file contains the solutions for the visible test cases, in <a href=\"https://docs.python.org/3/library/json.html\">JSON</a> format.  If the instructions are confusing you, please look at this file, to see if it can help to clear up your confusion.\n",
    "* `models`: This directory contains two MDP models. Especially, `models/model_small.json` is exactly the same as the one presented in the slides. If the slides are not available yet when you are doing this MP, please refer to <a href=\"https://courses.engr.illinois.edu/ece448/sp2022/slides/lec32.pdf\"> the slides for spring 2022</a>.\n",
    "* `utils.py`: This is an auxiliary program that you can use to load the model and visualize it.\n",
    "\n",
    "Please note that there is no extra packages that you should be using except for NumPy. (**Using exsiting MDP libraries would result in score 0!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file (`mp10_notebook.ipynb`) will walk you through the whole MP, giving you instructions and debugging tips as you go.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. <a href=\"#section1\">The MDP environment</a>\n",
    "1. <a href=\"#section2\">Value iteration</a>\n",
    "1. <a href=\"#grade\">Grade Your Homework</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## The MDP environment\n",
    "In this MP, you will implement the value iteration algorithm introduced in the class. The MDPs you will work on are similar to the grid world example mentioned in the class, but with __state-dependent transition and reward model__.\n",
    "\n",
    "### Loading the MDP model\n",
    "Helper functions are provided in ```utils.py```. Two predefined MDP models are given in ```models```. Please note that ```models/small.json``` defines exactly the same MDP model presented in the lecture, and you can use the intermediate results in the slides to debug your implementation. With function ```load_MDP(filename)```, you can load a MDP model as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "model = utils.load_MDP('models/model_small.json')\n",
    "### To load the other one, uncomment the following\n",
    "# model = utils.load_MDP('models/model_large.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded model ```model``` fully defines the MDP model as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4\n",
      "1.0\n",
      "(3, 4)\n",
      "(3, 4)\n",
      "(3, 4)\n",
      "(3, 4, 3)\n",
      "\n",
      "#################\n",
      "\n",
      "Help on method visualize in module utils:\n",
      "\n",
      "visualize(U=None) method of utils.GridWorld instance\n",
      "    This function visualizes the shape, the wall, and the terminal states of the environment. If a utility function U is provided, then it visualizes the utility function instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.M, model.N)\n",
    "print(model.gamma)\n",
    "print(model.W.shape)\n",
    "print(model.T.shape)\n",
    "print(model.R.shape)\n",
    "print(model.D.shape)\n",
    "print('\\n#################\\n')\n",
    "help(model.visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we explain the elements of the loaded model.\n",
    "\n",
    "### The states\n",
    "Simillar to the grid world presented in the class, the environment is a grid world with $M \\times N$ cells. $M$ and $N$ are accessible via ```model.M``` and ```model.N```. In the following, cell $(r, c)$ refers to the cell at the $r$-th row and $c$-th column. Each cell represents a state of the MDP.\n",
    "\n",
    "### The wall\n",
    "The $M \\times N$ boolean matrix ```model.W``` defines the wall in the environment. If ```model.W[r, c] == True```, then the cell $(r, c)$ is occupied by the wall.\n",
    "\n",
    "### The rewards\n",
    "The $M \\times N$ boolean matrix ```model.T``` defines the terminal states. ```model.T[r, c] == True``` if the cell $(r, c)$ is a _terminal state_, and ```T[r, c] == False``` otherwise.\n",
    "\n",
    "The $M \\times N$ matrix ```model.R``` defines the rewards. ```model.R[r, c]``` is the reward that the agent can get if it reaches the cell $(r, c)$. For terminal states, the reward will be either $+1$ or $-1$. For non-terminal states, the reward will be a small negative number.\n",
    "\n",
    "Furthermore, ```model.gamma``` is the discount factor $\\gamma$ you should use when computing the dicounted reward.\n",
    "\n",
    "### The actions\n",
    "At each non-terminal cell $(r, c)$, there are four available actions for the agent: move __left__, __up__, __right__, or __down__. However, due to environmental disturbances, the agent cannot always move as intended. Instead, an $M \\times N \\times 3$ numpy array is provided to define the movement and can be accessed as ```model.D```. Specifically, the actual movement of the agent will be along the intended direction with probability ```model.D[r, c, 0]```, and will be at the right angles to the intended direction with probability ```model.D[r, c, 1]``` (counter-clockwise) $+$ ```model.D[r, c, 2]``` (clockwise). It is guaranteed that the summation of these three probabilites is one. The next state of the agent will be the next cell along the actual moving direction. However, if the actual movement of the agent results in a collision with the boundary of environment or the wall, the agent will stay in the current cell.\n",
    "\n",
    "### Visualization\n",
    "We also provide a helper function for visualizing the environment, and the utility function. To use it, please run the following. In the figure, \"x\" marks a cell that is occupied by the wall. \"+1\" and \"-1\" mark the terminal states and their rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visualize the utility function. You can visualize the utility function at each iteration to see how it is being updated, which is helpful for debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "U = np.zeros([model.M, model.N])\n",
    "model.visualize(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate system\n",
    "Please be aware of the coordinate system we will use in this MP. In the above visualization, the cell at the upper-left corner is $(0, 0)$, the upper-right is $(0, 3)$, and bottom-left is $(2, 0)$. Moving up means moving from $(r, c)$ to $(r-1, c)$, moving right means from $(r, c)$ to $(r, c+1)$, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Value iteration\n",
    "As stated in the lecture, the utility of a state $s$ is the best possible expected sum of discounted rewards and denoted by $U(s)$. With value iteration, we can compute this function $U$. The algorithm proceeds as follows.\n",
    "\n",
    "We start with iteration $i = 0$ and simply initialize $U_i(s) = 0$ for all $s$. Then at each iteration, we update $U$ as follows\n",
    "$$\n",
    "U_{i+1}(s) = R(s) + \\gamma \\max_{a} \\sum_{s^\\prime} P(s^\\prime | s, a) U_{i}(s^\\prime).\n",
    "$$\n",
    "\n",
    "We keep doing this until convergence, i.e., when $|U_{i+1}(s) - U_i(s)| < \\epsilon$ for all $s$, where $\\epsilon > 0$ is a constant.\n",
    "\n",
    "In order to implement the algorithm, you need to complete the following functions in ```submitted.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the transition matrix $P$\n",
    "\n",
    "First, notice that the transition matrix $P(s' | s, a)$ will be called many times, and it will not change during the value iteration. Thus, it makes sense to precompute it before doing the value iteration. To this end, you need to complete the function ```compute_transition_matrix()```. This function takes in the MDP model ```model``` and computes the transition \"matrix\", which is actually an $M \\times N \\times 4 \\times M \\times N$ numpy array ```P```. In this function, you need to consider each state $(r, c)$ and each action $a \\in \\{0\\text{ (left)}, 1\\text{ (up)}, 2\\text{ (right)}, 3\\text{ (down)}\\}$. ```P[r, c, a, r', c']``` should be the probability that the agent will move from cell ```(r, c)``` to ```(r', c')``` if it takes action ```a```. Especially, if ```(r, c)``` is a terminal state, you can simply set ```P[r, c, :, :, :] = 0```, i.e., the probability that the agent move from a terminal state to any state (including itself) is $0$, since once the agent reaches a terminal state, the game is over.\n",
    "\n",
    "You may notice that the transition matrix ```P``` is very sparse, i.e., most of its elements are zeros. Better data structre such as sparse matrices can be used to improve the efficiency. But in this MP, we simply use a regular numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function compute_transition_matrix in module submitted:\n",
      "\n",
      "compute_transition_matrix(model)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import submitted, importlib\n",
    "importlib.reload(submitted)\n",
    "help(submitted.compute_transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you loaded the ```'models/model_small.json'``` MDP in the previous section, you can check some cells in the computed transition matrix to see if it is correct. For example, in the following, we check ```P[1, 0, 2, :, :]```. Recall that this should the probability distribution of the next state if the agent takes the action $2$ (right) at cell $(1, 0)$. Please also keep in mind that cell $(1, 1)$ is occupied by the wall. So, with probability $0.1$ the agent will move up to $(0, 0)$; with probability $0.1$ the agent will move down to $(2, 0)$; with probability $0.8$, it will move as intended (right) but will cause a collision to the wall, and thus the agent will stay at $(1, 0)$ with probability $0.8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.  0.  0. ]\n",
      " [0.8 0.  0.  0. ]\n",
      " [0.1 0.  0.  0. ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = submitted.compute_transition_matrix(model)\n",
    "print(P[1, 0, 2, :, :])\n",
    "model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the utility function\n",
    "\n",
    "Then, you need to complete the function ```update_utility```, which takes in the current utility function ```U_current``` (corresponding to the $U_i$ in the above equation) and computes the updated utility function ```U_next``` (corresponding to the $U_{i+1}$ in the above equation). This function should implement the update rule (the equation) in the value iteration algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function update_utility in module submitted:\n",
      "\n",
      "update_utility(model, P, U_current)\n",
      "    Parameters:\n",
      "    model - The MDP model returned by load_MDP()\n",
      "    P - The precomputed transition matrix returned by compute_transition_matrix()\n",
      "    U_current - The current utility function, which is an M x N array\n",
      "    \n",
      "    Output:\n",
      "    U_next - The updated utility function, which is an M x N array\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.update_utility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have represented the transition ```P``` and utility ```U_current``` as numpy arrays. The best way to implement this function is to use vectorization. That is, we can rewrite the update rule as some matrix operations and then use numpy's builtin functions to compute them. For example, the summation in the equation is actually an inner product of $P$ and $U_i$. Using numpy's ```dot``` function to compute this inner product is much faster than implementing it as a for loop. However, using vectorization is totally optional for you. The efficiency of your program will not contribute to your score. You will not get any extra credit even if you indeed use vectorization. So feel free to use for loop since it is much easier to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together\n",
    "\n",
    "Now, you are ready to complete the ```value_iteration``` function, which should first compute the ```P``` but calling ```compute_transition_matrix``` and then keeps calling ```update_utility``` until convergence. Please keep in mind that the convergence criterion is $|U_{i+1}(s) - U_i(s)| < \\epsilon$ for all $s$. In this MP, please use $\\epsilon = 10^{-3}$. In ```submitted.py```, you can find a predefined variable ```epsilon = 1e-3```. Also, please stop the program after a specifc number of iteration even if it has not converged. 100 iterations should be sufficient for all the tests in this MP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function value_iteration in module submitted:\n",
      "\n",
      "value_iteration(model, visualize=False)\n",
      "    Parameters:\n",
      "    model - The MDP model returned by load_MDP()\n",
      "    \n",
      "    Output:\n",
      "    U - The utility function, which is an M x N array\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.value_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of debugging, you can visualize the utility function at each iteration using the provided ```model.visualize(U_current)``` function to see how the utility is being updated. You can also compare your utility function to the ground truth presented in the slides. For example, the following code visualize the computed utility. You can compare it to the one in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "U = submitted.value_iteration(model)\n",
    "model.visualize(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>\n",
    "## Grade your homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've reached this point, and all of the above sections work, then you're ready to try grading your homework!  Before you submit it to Gradescope, try grading it on your own machine.  This will run some visible test cases (which you can read in `tests/test_visible.py`), and compare the results to the solutions (which you can read in `solution.json`).\n",
    "\n",
    "The exclamation point (!) tells python to run the following as a shell command.  Obviously you don't need to run the code this way -- this usage is here just to remind you that you can also, if you wish, run this command in a terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.098s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python grade.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got any 'E' marks, it means that your code generated some runtime errors, and you need to debug those.\n",
    "\n",
    "If you got any 'F' marks, it means that your code ran without errors, but that it generated results that are different from the solutions in `solutions.json`.  Try debugging those differences.\n",
    "\n",
    "If neither of those things happened, and your result was a series of dots, then your code works perfectly.  \n",
    "\n",
    "If you're not sure, you can try running grade.py with the -j option.  This will produce a JSON results file, in which the best score you can get is 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should try uploading `submitted.py` to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.  \n",
    "\n",
    "Gradescope will run the same visible tests that you just ran on your own machine, plus some additional hidden tests.  It's possible that your code passes all the visible tests, but fails the hidden tests.  If that happens, then it probably means that you hard-coded a number into your function definition, instead of using the input parameter that you were supposed to use.  Debug by running your function with a variety of different input parameters, and see if you can get it to respond correctly in all cases.\n",
    "\n",
    "Once your code works perfectly on Gradescope, with no errors, then you are done with the MP.  Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
